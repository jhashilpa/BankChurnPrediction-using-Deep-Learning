{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project - Bank Churn prediction\n",
    "\n",
    "##### Objective:\n",
    "Built a Classification model to predict if the customer will leave the bank in some time.\n",
    "\n",
    "##### Context:\n",
    " All service providers have to worry about problem of 'Churn' i.e. customers leaving and joining another service provider. It is advantageous for organizations like banks to know what leads a client towards the decision to leave the company.Management can concentrate efforts on improvement of service, keeping in mind these priorities.\n",
    "\n",
    "##### Data Description:\n",
    "The case study is from an open-source dataset from Kaggle.The dataset contains 10,000 sample points with 14 distinct features such as CustomerId, CreditScore, Geography, Gender, Age, Tenure, Balance etc. Link to the Kaggle project site:https://www.kaggle.com/mathchi/churn-for-bank-customers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing  standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bank.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RowNumber #CustomerId and #Surname are not required hence dropping it\n",
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,0:10].values # Credit Score through Estimated Salary - Independent Variables\n",
    "Y = df.iloc[:,10].values # Exited-Dependent column\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n"
     ]
    }
   ],
   "source": [
    "#Handling categorical columns -Gender and Country\n",
    "\n",
    "label_X_gender_encoder = LabelEncoder()\n",
    "X[:,2] = label_X_gender_encoder.fit_transform(X[:,2])\n",
    "\n",
    "countryhotencoder = ColumnTransformer([(\"countries\", OneHotEncoder(), [1])], remainder=\"passthrough\")\n",
    "X = countryhotencoder.fit_transform(X)\n",
    "\n",
    "#Dropping one of the dummy columns\n",
    "X = X[:,1:] \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing the inputs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating the batches for both training and test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the hyper-parameters\n",
    "\n",
    "input_features=11 #No of input neurons\n",
    "hidden1=6 #No of neurons in 1st hidden layer\n",
    "hidden2 =6 #No of neurons in 2nd hiddeln layer\n",
    "out_features=1 #No of Ouput neuron\n",
    "learning_rate=.001\n",
    "batch_size=32\n",
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. of batches in Training datset is :  266\n",
      "NO. of batches in Test datset is :  66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = TensorDataset(torch.FloatTensor(X_train.astype(float)),torch.FloatTensor(y_train.astype(float)))\n",
    "test_data = TensorDataset(torch.FloatTensor(X_test.astype(float)),torch.FloatTensor(y_test.astype(float)))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data,batch_size=batch_size, shuffle=False, drop_last=True)      \n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, drop_last=True)  \n",
    "print(\"NO. of batches in Training datset is : \",len(train_loader))\n",
    "print(\"NO. of batches in Test datset is : \",len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the basic ANN architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the architecture of  ANN model\n",
    "#CReating the ANN model\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self,input_features,hidden1,hidden2,out_features):\n",
    "        super().__init__()\n",
    "        self.f_connected1=nn.Linear(input_features,hidden1)\n",
    "        self.f_connected2=nn.Linear(hidden1,hidden2)\n",
    "        self.out=nn.Linear(hidden2,out_features)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.f_connected1(x))\n",
    "        x=F.relu(self.f_connected2(x))\n",
    "        x=F.sigmoid(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of ANN(\n",
       "  (f_connected1): Linear(in_features=11, out_features=6, bias=True)\n",
       "  (f_connected2): Linear(in_features=6, out_features=6, bias=True)\n",
       "  (out): Linear(in_features=6, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####instantiate the  ANN class\n",
    "torch.manual_seed(20)\n",
    "ANNModel=ANN(input_features,hidden1,hidden2,out_features)\n",
    "ANNModel.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining loss function & optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Backward Propogation-- Define the loss_function,define the optimizer\n",
    "loss_function=nn.BCEWithLogitsLoss()\n",
    "optimizer=torch.optim.Adam(ANNModel.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train(); # It is specially required when Dropout and Batch Normalization is implemented.\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Iterate through dataset\n",
    "    for data, target in train_loader:\n",
    "        target = target.unsqueeze(1)\n",
    "        \n",
    "        # Zero grad\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print average loss\n",
    "    print(\"Train Epoch: {}\\t Loss: {:.6f}\".format(epoch, total_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval() #It is specially required when Dropout and Batch Normalization is implemented.\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            target = target.unsqueeze(1)\n",
    "            \n",
    "            output = model(data)\n",
    "            test_loss += loss_function(output, target).item()\n",
    "            pred = output>=0.5\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhash\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\t Loss: 0.026636\n",
      "\n",
      "Test set: Average loss: 0.0240, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 1\t Loss: 0.023448\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 2\t Loss: 0.023099\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 3\t Loss: 0.023055\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 4\t Loss: 0.023035\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 5\t Loss: 0.023022\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 6\t Loss: 0.023006\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 7\t Loss: 0.022986\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 8\t Loss: 0.022958\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 9\t Loss: 0.022925\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 10\t Loss: 0.022887\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 11\t Loss: 0.022842\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1635/2000 (81.750%)\n",
      "\n",
      "Train Epoch: 12\t Loss: 0.022795\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1645/2000 (82.250%)\n",
      "\n",
      "Train Epoch: 13\t Loss: 0.022754\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1645/2000 (82.250%)\n",
      "\n",
      "Train Epoch: 14\t Loss: 0.022723\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1651/2000 (82.550%)\n",
      "\n",
      "Train Epoch: 15\t Loss: 0.022699\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1652/2000 (82.600%)\n",
      "\n",
      "Train Epoch: 16\t Loss: 0.022682\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1650/2000 (82.500%)\n",
      "\n",
      "Train Epoch: 17\t Loss: 0.022670\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1651/2000 (82.550%)\n",
      "\n",
      "Train Epoch: 18\t Loss: 0.022659\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1653/2000 (82.650%)\n",
      "\n",
      "Train Epoch: 19\t Loss: 0.022651\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1653/2000 (82.650%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Training and Testing the ANN Model\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    train(ANNModel, train_loader, optimizer, epoch)\n",
    "    test(ANNModel, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of a basic ANN model is around 82.5 % after training for 20 epochs. \n",
    "\n",
    "#### It seems Accuracy is not improving much ;Other techniques can be implemented to expect betterperformance.\n",
    "#### We will be implementing following techniques:\n",
    "#### 1>Batch Normalization \n",
    "####  2>Drop Out layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Implementing Batch Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating ANN architecture and introducing Batch Normalization of internal outputs of hidden layers\n",
    "\n",
    "class BNAnn(nn.Module):\n",
    "    def __init__(self,input_features,hidden1,hidden2,out_features): \n",
    "        super().__init__()\n",
    "        self.model_BNN = nn.Sequential(\n",
    "            nn.Linear(input_features,hidden1),\n",
    "            nn.BatchNorm1d(hidden1), #applying batch norm before the output of activation function of first hidden layers\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden1, hidden2),\n",
    "            nn.BatchNorm1d(hidden2),  #applying batch norm before the output of activation function of secon hidden layer \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden2, out_features),\n",
    "            nn.BatchNorm1d(out_features),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "             \n",
    "    def forward(self, x):\n",
    "        x = self.model_BNN(x)\n",
    "        return x\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of BNAnn(\n",
       "  (model_BNN): Sequential(\n",
       "    (0): Linear(in_features=11, out_features=6, bias=True)\n",
       "    (1): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=6, out_features=6, bias=True)\n",
       "    (4): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=6, out_features=1, bias=True)\n",
       "    (7): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): Sigmoid()\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####instantiate the  Batch Normalization  Model\n",
    "torch.manual_seed(20)\n",
    "BNAnnModel=BNAnn(input_features,hidden1,hidden2,out_features)\n",
    "BNoptimizer=torch.optim.Adam(BNAnnModel.parameters(),lr=learning_rate)\n",
    "BNAnnModel.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\t Loss: 0.028368\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 1345/2000 (67.250%)\n",
      "\n",
      "Train Epoch: 1\t Loss: 0.026772\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 1512/2000 (75.600%)\n",
      "\n",
      "Train Epoch: 2\t Loss: 0.025922\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 1549/2000 (77.450%)\n",
      "\n",
      "Train Epoch: 3\t Loss: 0.025328\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 1571/2000 (78.550%)\n",
      "\n",
      "Train Epoch: 4\t Loss: 0.024839\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 1583/2000 (79.150%)\n",
      "\n",
      "Train Epoch: 5\t Loss: 0.024476\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 1597/2000 (79.850%)\n",
      "\n",
      "Train Epoch: 6\t Loss: 0.024182\n",
      "\n",
      "Test set: Average loss: 0.0240, Accuracy: 1621/2000 (81.050%)\n",
      "\n",
      "Train Epoch: 7\t Loss: 0.023894\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 1656/2000 (82.800%)\n",
      "\n",
      "Train Epoch: 8\t Loss: 0.023650\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1669/2000 (83.450%)\n",
      "\n",
      "Train Epoch: 9\t Loss: 0.023457\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1671/2000 (83.550%)\n",
      "\n",
      "Train Epoch: 10\t Loss: 0.023314\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1677/2000 (83.850%)\n",
      "\n",
      "Train Epoch: 11\t Loss: 0.023202\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1674/2000 (83.700%)\n",
      "\n",
      "Train Epoch: 12\t Loss: 0.023115\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1676/2000 (83.800%)\n",
      "\n",
      "Train Epoch: 13\t Loss: 0.023037\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1672/2000 (83.600%)\n",
      "\n",
      "Train Epoch: 14\t Loss: 0.022974\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1676/2000 (83.800%)\n",
      "\n",
      "Train Epoch: 15\t Loss: 0.022913\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1681/2000 (84.050%)\n",
      "\n",
      "Train Epoch: 16\t Loss: 0.022864\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1683/2000 (84.150%)\n",
      "\n",
      "Train Epoch: 17\t Loss: 0.022828\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1686/2000 (84.300%)\n",
      "\n",
      "Train Epoch: 18\t Loss: 0.022786\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1687/2000 (84.350%)\n",
      "\n",
      "Train Epoch: 19\t Loss: 0.022756\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1680/2000 (84.000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing the BNAnnModel\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    train(BNAnnModel, train_loader, BNoptimizer, epoch)\n",
    "    test(BNAnnModel, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Accuracy of a  ANN model  after introducing Batch Normalization is around 84.4 % after training for 19 epochs whic is better than that of basic ANN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Drop Out Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating ANN architecture by introducing Drop Out layer.Initialized p values as 0.2 for both of the hidden layers\n",
    "\n",
    "class DropOutAnn(nn.Module):\n",
    "    def __init__(self,input_features,hidden1,hidden2,out_features): \n",
    "        super().__init__()\n",
    "        self.model_dropout = nn.Sequential(\n",
    "            nn.Linear(input_features,hidden1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden1,hidden2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden2,out_features),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "             \n",
    "    def forward(self, x):\n",
    "        x = self.model_dropout(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "####instantiate the  DropOutAnn Model\n",
    "\n",
    "DropOutAnnModel=DropOutAnn(input_features,hidden1,hidden2,out_features)\n",
    "DropOutoptimizer=torch.optim.Adam(DropOutAnnModel.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\t Loss: 0.028805\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 1\t Loss: 0.025359\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 2\t Loss: 0.024348\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 3\t Loss: 0.024049\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 4\t Loss: 0.023936\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 5\t Loss: 0.023885\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 6\t Loss: 0.023825\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 7\t Loss: 0.023697\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 8\t Loss: 0.023650\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 9\t Loss: 0.023569\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 10\t Loss: 0.023499\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 11\t Loss: 0.023456\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1574/2000 (78.700%)\n",
      "\n",
      "Train Epoch: 12\t Loss: 0.023354\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1598/2000 (79.900%)\n",
      "\n",
      "Train Epoch: 13\t Loss: 0.023255\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1607/2000 (80.350%)\n",
      "\n",
      "Train Epoch: 14\t Loss: 0.023206\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1614/2000 (80.700%)\n",
      "\n",
      "Train Epoch: 15\t Loss: 0.023135\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1616/2000 (80.800%)\n",
      "\n",
      "Train Epoch: 16\t Loss: 0.023106\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1616/2000 (80.800%)\n",
      "\n",
      "Train Epoch: 17\t Loss: 0.023056\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1616/2000 (80.800%)\n",
      "\n",
      "Train Epoch: 18\t Loss: 0.023054\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1617/2000 (80.850%)\n",
      "\n",
      "Train Epoch: 19\t Loss: 0.023017\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1617/2000 (80.850%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training and testing the DropOutAnnModel\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    train(DropOutAnnModel, train_loader, DropOutoptimizer, epoch)\n",
    "    test(DropOutAnnModel, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy has been improved in the model where Batch Normalization is implemented . Accuracy is around 84.5 % which is the   highest amongs all three models.\n",
    "### Accuracy of ANN model with Drop Out Implementation is around 82.%\n",
    "#### Accuracy of a basic ANN Model is around 81% which is the least amongst all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "#### 1> Batch Normalization helped in improving the accuracy of the Model by 3.5% .\n",
    "#### 2>Drop Out didnt help much in increasing the Accuracy which makes sense as no. of  neurons is  very less in each hidden layer(We can't increase it much as no of inputs are also not very large) and with the results its seems that model is not overfitted . Drop Out layer provides good resulst when the model is overfitted which is not the case here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
